{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries and define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import itertools\n",
    "from pathlib import Path\n",
    "\n",
    "np.set_printoptions(precision=3, linewidth=120, suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_lambda(A, func=None, addremove=1, p=False):\n",
    "    \"\"\"Calculate the current lambda_2 and K_lambda_2 and return them.\"\"\"\n",
    "    D = np.diag(A.sum(1))\n",
    "    L = D - A\n",
    "    lambdas, vectors = np.linalg.eigh(L)\n",
    "    sort = lambdas.argsort()\n",
    "    lambdas = lambdas[sort]\n",
    "    vectors = vectors[:,sort]\n",
    "\n",
    "    l2 = lambdas[1]\n",
    "    f = vectors[:,1]\n",
    "    l2_multiplicity = np.count_nonzero(np.isclose(lambdas, l2))\n",
    "\n",
    "    K_l2 = 0\n",
    "    s_val = 0\n",
    "    pairs = None\n",
    "    if func is not None:\n",
    "        search = np.empty_like(A)\n",
    "        search[:] = np.nan\n",
    "        for i, j in itertools.combinations(range(len(f)), 2):\n",
    "            if abs(f[i] - f[j]) > 10e-5 and ((addremove == 1 and A[i][j] == 0) or (addremove == -1 and A[i][j] == 1)):\n",
    "                search[i][j] = addremove * (f[i] - f[j]) ** 2\n",
    "\n",
    "            if A[i][j] == 1:\n",
    "                K_l2 = max(K_l2, (f[i] - f[j]) ** 2)\n",
    "\n",
    "        s_val = func(search)\n",
    "        if l2_multiplicity == 1 or addremove == -1:\n",
    "            pairs = {tuple(p) for p in np.argwhere(np.isclose(search, s_val))}\n",
    "        else:\n",
    "            pairs = f'Unknown, at least {l2_multiplicity} links'\n",
    "\n",
    "\n",
    "\n",
    "    if p:\n",
    "        print(f\"({l2:.5f}, {K_l2:.5f})\")\n",
    "        print(f\"L  = {np.array2string(L, prefix='L  = ')}\")\n",
    "        print(f\"eval={np.array2string(lambdas)}\")\n",
    "        print(f\"evec={np.array2string(vectors, prefix='evec=')}\")\n",
    "        print('-----------------------------------------------\\n')\n",
    "\n",
    "    return round(l2, 5), round(K_l2 * 0.2, 5), pairs, f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_graphs(graphs, figsize=14, dotsize=20):\n",
    "    \"\"\"Utility to plot a lot of graphs from an array of graphs.\n",
    "    Each graphs is a list of edges; each edge is a tuple.\"\"\"\n",
    "    fig = plt.figure(figsize=(figsize,figsize))\n",
    "    fig.patch.set_facecolor('white') # To make copying possible (no transparent background)\n",
    "    k = int(np.sqrt(len(graphs)))\n",
    "    for i, g in enumerate(graphs):\n",
    "        plt.subplot(k+1,k+1,i+1)\n",
    "        G = nx.from_numpy_array(graphs[g])\n",
    "        nx.draw_kamada_kawai(G, node_size=dotsize)\n",
    "        plt.title(f\"Graph {g} - {len(G.edges)}\\n{calc_lambda(graphs[g], np.nanmin)[:2]}\")\n",
    "        print('.', end='')\n",
    "\n",
    "#plot_graphs([[(0,1),(1,2),(1,3)]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load graphs and plot them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "# Make the graphs and plot them.\n",
    "NV = 6  # Number of nodes in the graph.\n",
    "data_folder = Path.cwd() / '../Data'\n",
    "\n",
    "\n",
    "with open(data_folder / f'UniqueGraphs_{NV}.npz', 'rb') as stream:\n",
    "    loaded = np.load(stream)\n",
    "    gs = OrderedDict(loaded)\n",
    "\n",
    "print(f'Drawing {len(gs)} graphs...')\n",
    "plot_graphs(gs, figsize=30, dotsize=20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Possible values of lambda_2 depending on the number of edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "l2_by_edges = defaultdict(list)\n",
    "\n",
    "for i, A in enumerate(gs.values()):\n",
    "    # print(f\"Graph {i}\", end=' ')\n",
    "    l2 = calc_lambda(A, None)[0]\n",
    "    l2_by_edges[np.count_nonzero(A == 1) / 2].append(l2)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = sorted(l2_by_edges.keys())\n",
    "data_len = max(len(v) for v in l2_by_edges.values())\n",
    "data = [[0 for _ in range(len(labels))] for _ in range(data_len)]\n",
    "\n",
    "for i, lab in enumerate(labels):\n",
    "    for j, v in enumerate(sorted(l2_by_edges[lab])):\n",
    "        data[j][i] = v\n",
    "\n",
    "        \n",
    "fig, (ax1, ax2, ax3) = plt.subplots(3, 1)\n",
    "fig.set_size_inches(16, 18) \n",
    "rects = []\n",
    "\n",
    "# 1st axes\n",
    "x = np.arange(len(labels))  # the label locations\n",
    "width = 0.9  # the width of the bars\n",
    "for i in range(data_len):\n",
    "    rec = ax1.bar(x + i * width / data_len, data[i], width / data_len)\n",
    "    ax1.bar_label(rec, labels=[f'{v:.3f}' if v > 0 else '' for v in data[i]],\n",
    "                padding=3, fmt='%.3f', rotation='vertical')\n",
    "ax1.set_title('Possible $\\lambda_2$ by number of edges')\n",
    "ax1.set_ylabel('$\\lambda_2$')\n",
    "ax1.set_xlabel('Num edges')\n",
    "ax1.set_xticks(x, labels)\n",
    "ax1.grid(axis='y')\n",
    "\n",
    "# 2nd axes - line plot\n",
    "possible_l2 = sorted(set(l2 for temp in data for l2 in temp))\n",
    "max_l2 = possible_l2[-1]\n",
    "x = np.linspace(0, max_l2, 500)\n",
    "y = []\n",
    "i = 1\n",
    "for xi in x:\n",
    "    while xi > possible_l2[i]:\n",
    "        i += 1\n",
    "    y.append(min(xi - possible_l2[i-1], possible_l2[i] - xi))\n",
    "ax2.plot(x, y)\n",
    "ax2.set_title('Needed $K_{\\lambda_2}$ for specified $\\lambda_2$')\n",
    "ax2.set_ylabel('Minimum $K_{\\lambda_2}$')\n",
    "ax2.set_xlabel('Reference $\\lambda_2$')\n",
    "ax2.grid()\n",
    "\n",
    "# 2nd axes - error bars\n",
    "#possible_l2 = sorted(set(l2 for temp in data for l2 in temp))\n",
    "#print(possible_l2)\n",
    "#max_l2 = possible_l2[-1]\n",
    "#x = np.linspace(0, max_l2, 500)\n",
    "#y = x\n",
    "\n",
    "#i = 1\n",
    "#yerr = []\n",
    "#for xi in x:\n",
    "#    if xi > possible_l2[i]:\n",
    "#        i += 1\n",
    "#    yerr.append(min(xi - possible_l2[i-1], possible_l2[i] - xi))\n",
    "#ax2.errorbar(x, y, yerr=yerr)\n",
    "\n",
    "# 3rd axes - scatter plot\n",
    "y = np.ones((1, len(possible_l2)))\n",
    "x = possible_l2\n",
    "ax3.scatter(x, y, s=20)\n",
    "ax3.set_title('Possible values of $\\lambda_2$')\n",
    "ax3.set_xlabel('$\\lambda_2$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze lambda_2 changes when changing link values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as pgo\n",
    "import plotly.subplots as psub\n",
    "from Utils.plotting_funcs import plotly_nx\n",
    "\n",
    "\n",
    "def make_analysis(k, A_start, p=False):\n",
    "    x = np.linspace(0, 1, 50)\n",
    "    N = A_start.shape[0]\n",
    "\n",
    "    # Initial lambda value and max change estimate.\n",
    "    init_lambda, addmax_est, addmax_links, f = calc_lambda(A_start, np.nanmax, addremove=1, p=False)\n",
    "    _, addmin_est, addmin_links, _ = calc_lambda(A_start, np.nanmin, addremove=1, p=False)\n",
    "    _, remmax_est, remmax_links, _ = calc_lambda(A_start, np.nanmax, addremove=-1, p=False)\n",
    "    _, remmin_est, remmin_links, _ = calc_lambda(A_start, np.nanmin, addremove=-1, p=False)\n",
    "\n",
    "    sens_data = {}\n",
    "    trend = {}\n",
    "    for i in range(0, N):\n",
    "        for j in range(i + 1, N):\n",
    "            sens_data[(i,j)] = []\n",
    "            A = A_start.copy()\n",
    "\n",
    "            # Calculate continuous changes in l2 when changing links.\n",
    "            for t in x:\n",
    "                A[i][j] = t\n",
    "                A[j][i] = t\n",
    "                l2 = calc_lambda(A, None)[0]\n",
    "                sens_data[(i, j)].append(l2)\n",
    "                trend[(i, j)] = 'dash' if A_start[i][j] else 'solid'\n",
    "\n",
    "            # Something else\n",
    "\n",
    "    # Make plots.\n",
    "    fig = psub.make_subplots(rows=1, cols=2)\n",
    "    nodes, edges = plotly_nx(nx.from_numpy_array(A_start))\n",
    "    fig.add_trace(nodes, row=1, col=1)\n",
    "    fig.add_trace(edges, row=1, col=1)\n",
    "    for edge in sens_data:\n",
    "        fig.add_trace(\n",
    "            pgo.Scatter(x=x, y=sens_data[edge], name=str(edge),\n",
    "                        mode='lines', line=dict(dash=trend[edge])),\n",
    "            row=1, col=2\n",
    "        )\n",
    "    fig.update_layout(title=dict(text=f'Graph {k} (l2 = {init_lambda}, f = {f})'),\n",
    "                      width=750, height=600,\n",
    "                      margin=dict(l=50, r=50, t=80, b=200),\n",
    "                      )\n",
    "\n",
    "    # Print results.\n",
    "    def gen_annot(est, links,):\n",
    "        return (f'Estimated delta = {est}<br>'\n",
    "                f'Links maximizing delta = {links}<br>')\n",
    "    annot_kwargs = dict(align='left', showarrow=False, xref='paper', yref='paper')\n",
    "\n",
    "    fig.add_annotation(text=\"<b>Adding max link</b><br>\" + gen_annot(addmax_est, addmax_links), x=0.0, y=-0.3, **annot_kwargs)\n",
    "    fig.add_annotation(text=\"<b>Adding min link</b><br>\" + gen_annot(addmin_est, addmin_links), x=0.0, y=-0.5, **annot_kwargs)\n",
    "    fig.add_annotation(text=\"<b>Removing max link</b><br>\" + gen_annot(remmax_est, remmax_links), x=1, y=-0.3, **annot_kwargs)\n",
    "    fig.add_annotation(text=\"<b>Removing min link</b><br>\" + gen_annot(remmin_est, remmin_links), x=1, y=-0.5, **annot_kwargs)\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "for k, A_start in enumerate(gs.values()):\n",
    "    make_analysis(k, A_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Check the consistency of $$\\Delta \\lambda_{2, max} = \\max(f_i - f_j)^2$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "count = Counter()\n",
    "\n",
    "\n",
    "for k, A_start in enumerate(gs):\n",
    "    if k in []:\n",
    "        debug = True\n",
    "    else:\n",
    "        debug = False\n",
    "    init_lambda, delta_est, init_links, _ = calc_lambda(A_start, np.nanmax, addremove=1, p=debug)\n",
    "\n",
    "    n = A_start.shape[0]\n",
    "    max_lambda = init_lambda\n",
    "    max_links = set()\n",
    "    for i in range(0, NV):\n",
    "        for j in range(i + 1, NV):\n",
    "            if A_start[i][j] == 0:\n",
    "                A = A_start.copy()\n",
    "                A[i][j] = 1\n",
    "                A[j][i] = 1\n",
    "\n",
    "                new_lambda = calc_lambda(A, np.nanmax)[0]\n",
    "                if (new_lambda - max_lambda) > 10e-5:\n",
    "                    max_lambda = new_lambda\n",
    "                    max_links = {(i, j)}\n",
    "                elif abs(new_lambda - max_lambda) < 10e-5 and abs(new_lambda - init_lambda) > 10e-5:\n",
    "                    max_links.add((i, j))\n",
    "\n",
    "    print(f'Graph {k}...', end=' ')\n",
    "\n",
    "    if max_links == init_links or not max_links or init_links.issubset(max_links):\n",
    "        out = 'OK'\n",
    "    elif max_links.issubset(init_links):\n",
    "        out = 'Partial'\n",
    "    else:\n",
    "        out = 'FAIL'\n",
    "        make_analysis(k, A_start)\n",
    "    count[out] += 1\n",
    "\n",
    "    print(f'{out} (l2o={init_lambda}, l2f={max_lambda}, est={init_links}, act={max_links})', flush=True)\n",
    "\n",
    "total = sum(count.values())\n",
    "print('=========================')\n",
    "print(f\"OK     : {count['OK']}/{total} [{count['OK'] / total * 100:.2f} %]\")\n",
    "print(f\"Partial: {count['Partial']}/{total} [{count['Partial'] / total * 100:.2f} %]\")\n",
    "print(f\"FAIL   : {count['FAIL']}/{total} [{count['FAIL'] / total * 100:.2f} %]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def select_link(A, addremove):\n",
    "    L = np.diag(A.sum(1)) - A\n",
    "    lambdas, vectors = np.linalg.eigh(L)\n",
    "    sort = lambdas.argsort()\n",
    "    lambdas = lambdas[sort]\n",
    "    vectors = vectors[:, sort]\n",
    "\n",
    "    l2 = lambdas[1]\n",
    "    f = vectors[:, 1]\n",
    "\n",
    "    search = []\n",
    "    f = np.around(f, 4)\n",
    "    for i, j in itertools.combinations(range(len(f)), 2):\n",
    "        if abs(f[i] - f[j]) > 10e-5 and ((addremove == \"ADD\" and A[i][j] == 0) or (addremove == \"REM\" and A[i][j] == 1)):\n",
    "            search.append((round((f[i] - f[j]) ** 2, 4), (i, j)))\n",
    "\n",
    "    if not search:\n",
    "        return None\n",
    "\n",
    "    if addremove == \"ADD\":\n",
    "        f_val, link = max(search)\n",
    "    else:\n",
    "        f_val, link = min(search)\n",
    "\n",
    "    return l2, f_val, link\n",
    "\n",
    "\n",
    "starting_graph = 'G6,102'\n",
    "ref_lambda = [1, 3, 2]\n",
    "\n",
    "data_folder = Path.cwd() / '../Data'\n",
    "with open(data_folder / f'UniqueGraphs_{starting_graph[1]}.npz', 'rb') as stream:\n",
    "    loaded = np.load(stream)\n",
    "    graphs = {x: loaded[x] for x in loaded}\n",
    "\n",
    "k = 0\n",
    "A = graphs[starting_graph]\n",
    "history = [A.copy()]\n",
    "addremove = \"ADD\"\n",
    "l2 = 0\n",
    "\n",
    "for ref in ref_lambda:\n",
    "    user_input = 'Y'\n",
    "\n",
    "    print(f'ref={ref}')\n",
    "    while user_input != 'n':\n",
    "        l2, _, _, = select_link(A, addremove)\n",
    "\n",
    "        if l2 < ref - 0.2:\n",
    "            addremove = \"ADD\"\n",
    "        elif l2 > ref + 0.2:\n",
    "            addremove = \"REM\"\n",
    "        else:\n",
    "            break\n",
    "\n",
    "        _, _, pair, = select_link(A, addremove)\n",
    "        val = 1 if addremove == \"ADD\" else 0\n",
    "        A[pair[0]][pair[1]] = val\n",
    "        A[pair[1]][pair[0]] = val\n",
    "        history.append(A.copy())\n",
    "\n",
    "        print(f\"k={k} | l2={l2:6.4f} {addremove} {pair}' > Continue? (Y/n)\", flush=True)\n",
    "        time.sleep(0.5)\n",
    "        user_input = input()\n",
    "\n",
    "        k += 1\n",
    "\n",
    "\n",
    "for k, A in enumerate(history):\n",
    "   make_analysis(k, A)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (topocon)",
   "language": "python",
   "name": "pycharm-f152e988"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
