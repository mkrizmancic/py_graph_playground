{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries and define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import itertools\n",
    "from pathlib import Path\n",
    "\n",
    "np.set_printoptions(precision=3, linewidth=120, suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_lambda_old(A, func=None, addremove=1, p=False):\n",
    "    \"\"\"Calculate the current lambda_2 and K_lambda_2 and return them.\"\"\"\n",
    "    D = np.diag(A.sum(1))\n",
    "    L = D - A\n",
    "    lambdas, vectors = np.linalg.eigh(L)\n",
    "    sort = lambdas.argsort()\n",
    "    lambdas = lambdas[sort]\n",
    "    vectors = vectors[:,sort]\n",
    "\n",
    "    l2 = lambdas[1]\n",
    "    f = vectors[:,1]\n",
    "    l2_multiplicity = np.count_nonzero(np.isclose(lambdas, l2))\n",
    "\n",
    "    K_l2 = 0\n",
    "    s_val = 0\n",
    "    pairs = None\n",
    "    if func is not None:\n",
    "        search = np.empty_like(A)\n",
    "        search[:] = np.nan\n",
    "        for i, j in itertools.combinations(range(len(f)), 2):\n",
    "            if abs(f[i] - f[j]) > 10e-5 and ((addremove == 1 and A[i][j] == 0) or (addremove == -1 and A[i][j] == 1)):\n",
    "                search[i][j] = addremove * (f[i] - f[j]) ** 2\n",
    "\n",
    "            if A[i][j] == 1:\n",
    "                K_l2 = max(K_l2, (f[i] - f[j]) ** 2)\n",
    "\n",
    "        s_val = func(search)\n",
    "        if l2_multiplicity == 1 or addremove == -1:\n",
    "            pairs = {tuple(p) for p in np.argwhere(np.isclose(search, s_val))}\n",
    "        else:\n",
    "            pairs = f'Unknown, at least {l2_multiplicity} links'\n",
    "\n",
    "\n",
    "\n",
    "    if p:\n",
    "        print(f\"({l2:.5f}, {K_l2:.5f})\")\n",
    "        print(f\"L  = {np.array2string(L, prefix='L  = ')}\")\n",
    "        print(f\"eval={np.array2string(lambdas)}\")\n",
    "        print(f\"evec={np.array2string(vectors, prefix='evec=')}\")\n",
    "        print('-----------------------------------------------\\n')\n",
    "\n",
    "    return round(l2, 5), round(K_l2 * 0.2, 5), pairs, f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_lambda(A):\n",
    "    \"\"\"Calculate the current lambda_2 and K_lambda_2 and return them.\"\"\"\n",
    "    D = np.diag(A.sum(1))\n",
    "    L = D - A\n",
    "    lambdas, vectors = np.linalg.eigh(L)\n",
    "    sort = lambdas.argsort()\n",
    "    lambdas = lambdas[sort]\n",
    "    vectors = vectors[:,sort]\n",
    "\n",
    "    l2 = lambdas[1]\n",
    "    f = vectors[:,1]\n",
    "    l2_multiplicity = np.count_nonzero(np.isclose(lambdas, l2))\n",
    "    \n",
    "    return round(l2, 5), l2_multiplicity, f\n",
    "\n",
    "def plot_graphs(graphs, figsize=14, dotsize=20):\n",
    "    \"\"\"Utility to plot a lot of graphs from an array of graphs.\n",
    "    Each graphs is a list of edges; each edge is a tuple.\"\"\"\n",
    "    fig = plt.figure(figsize=(figsize,figsize))\n",
    "    fig.patch.set_facecolor('white') # To make copying possible (no transparent background)\n",
    "    k = int(np.sqrt(len(graphs)))\n",
    "    for i, g in enumerate(graphs):\n",
    "        plt.subplot(k+1,k+1,i+1)\n",
    "        G = nx.from_numpy_array(graphs[g])\n",
    "        nx.draw_kamada_kawai(G, node_size=dotsize)\n",
    "        l2, mul, _ = calc_lambda(graphs[g])\n",
    "        plt.title(f\"Graph {g} - {len(G.edges)}\\nl2={l2} (x{mul})\")\n",
    "        print('.', end='')\n",
    "\n",
    "#plot_graphs([[(0,1),(1,2),(1,3)]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load graphs and plot them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "# Make the graphs and plot them.\n",
    "NV = 6  # Number of nodes in the graph.\n",
    "data_folder = Path.cwd() / '../Data'\n",
    "\n",
    "\n",
    "with open(data_folder / f'UniqueGraphs_{NV}.npz', 'rb') as stream:\n",
    "    loaded = np.load(stream)\n",
    "    gs = OrderedDict(loaded)\n",
    "\n",
    "print(f'Drawing {len(gs)} graphs...')\n",
    "plot_graphs(gs, figsize=30, dotsize=20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Possible values of lambda_2 depending on the number of edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "l2_by_edges = defaultdict(list)\n",
    "\n",
    "for i, A in enumerate(gs.values()):\n",
    "    # print(f\"Graph {i}\", end=' ')\n",
    "    l2 = calc_lambda(A)[0]\n",
    "    l2_by_edges[np.count_nonzero(A == 1) / 2].append(l2)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = sorted(l2_by_edges.keys())\n",
    "data_len = max(len(v) for v in l2_by_edges.values())\n",
    "data = [[0 for _ in range(len(labels))] for _ in range(data_len)]\n",
    "\n",
    "for i, lab in enumerate(labels):\n",
    "    for j, v in enumerate(sorted(l2_by_edges[lab])):\n",
    "        data[j][i] = v\n",
    "\n",
    "        \n",
    "fig, (ax1, ax2, ax3) = plt.subplots(3, 1)\n",
    "fig.set_size_inches(16, 18) \n",
    "rects = []\n",
    "\n",
    "# 1st axes\n",
    "x = np.arange(len(labels))  # the label locations\n",
    "width = 0.9  # the width of the bars\n",
    "for i in range(data_len):\n",
    "    rec = ax1.bar(x + i * width / data_len, data[i], width / data_len)\n",
    "    ax1.bar_label(rec, labels=[f'{v:.3f}' if v > 0 else '' for v in data[i]],\n",
    "                padding=3, fmt='%.3f', rotation='vertical')\n",
    "ax1.set_title('Possible $\\lambda_2$ by number of edges')\n",
    "ax1.set_ylabel('$\\lambda_2$')\n",
    "ax1.set_xlabel('Num edges')\n",
    "ax1.set_xticks(x, labels)\n",
    "ax1.grid(axis='y')\n",
    "\n",
    "# 2nd axes - line plot\n",
    "possible_l2 = sorted(set(l2 for temp in data for l2 in temp))\n",
    "max_l2 = possible_l2[-1]\n",
    "x = np.linspace(0, max_l2, 500)\n",
    "y = []\n",
    "i = 1\n",
    "for xi in x:\n",
    "    while xi > possible_l2[i]:\n",
    "        i += 1\n",
    "    y.append(min(xi - possible_l2[i-1], possible_l2[i] - xi))\n",
    "ax2.plot(x, y)\n",
    "ax2.set_title('Needed $K_{\\lambda_2}$ for specified $\\lambda_2$')\n",
    "ax2.set_ylabel('Minimum $K_{\\lambda_2}$')\n",
    "ax2.set_xlabel('Reference $\\lambda_2$')\n",
    "ax2.grid()\n",
    "\n",
    "# 2nd axes - error bars\n",
    "#possible_l2 = sorted(set(l2 for temp in data for l2 in temp))\n",
    "#print(possible_l2)\n",
    "#max_l2 = possible_l2[-1]\n",
    "#x = np.linspace(0, max_l2, 500)\n",
    "#y = x\n",
    "\n",
    "#i = 1\n",
    "#yerr = []\n",
    "#for xi in x:\n",
    "#    if xi > possible_l2[i]:\n",
    "#        i += 1\n",
    "#    yerr.append(min(xi - possible_l2[i-1], possible_l2[i] - xi))\n",
    "#ax2.errorbar(x, y, yerr=yerr)\n",
    "\n",
    "# 3rd axes - scatter plot\n",
    "y = np.ones((1, len(possible_l2)))\n",
    "x = possible_l2\n",
    "ax3.scatter(x, y, s=20)\n",
    "ax3.set_title('Possible values of $\\lambda_2$')\n",
    "ax3.set_xlabel('$\\lambda_2$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze lambda_2 changes when changing link values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "\n",
    "Res = namedtuple('Res', ['pair', 'best'])\n",
    "\n",
    "def first_approx_Ghosh(A, addremove):\n",
    "    l2, l2_multiplicity, f = calc_lambda(A)\n",
    "\n",
    "    pairs = None\n",
    "    best = None\n",
    "    \n",
    "    if l2_multiplicity == 1:\n",
    "        search = np.zeros_like(A)\n",
    "        search[:] = np.nan\n",
    "        pairs = {}\n",
    "        for i, j in itertools.combinations(range(len(f)), 2):\n",
    "            if (addremove == 1 and A[i][j] == 0) or (addremove == -1 and A[i][j] == 1):\n",
    "                approx = (f[i] - f[j]) ** 2\n",
    "                pairs[(i, j)] = round(approx, 2) * addremove\n",
    "                if abs(f[i] - f[j]) > 10e-5:\n",
    "                    search[i][j] = approx * addremove\n",
    "                    \n",
    "        s_val = np.nanmax(search)\n",
    "\n",
    "        best = {tuple(p) for p in np.argwhere(np.isclose(search, s_val))}\n",
    "\n",
    "    # if p:\n",
    "    #     print(f\"({l2:.5f}, {K_l2:.5f})\")\n",
    "    #     print(f\"L  = {np.array2string(L, prefix='L  = ')}\")\n",
    "    #     print(f\"eval={np.array2string(lambdas)}\")\n",
    "    #     print(f\"evec={np.array2string(vectors, prefix='evec=')}\")\n",
    "    #     print('-----------------------------------------------\\n')\n",
    "\n",
    "    return l2, l2_multiplicity, f, Res(pairs, best)\n",
    "\n",
    "def second_approx_He(A, addremove):\n",
    "    n = np.size(A, 1)\n",
    "    \n",
    "    D = np.diag(A.sum(1))\n",
    "    Q = D - A\n",
    "    \n",
    "    eps = 0.5 / np.max(D)\n",
    "    \n",
    "    R = np.eye(n) - eps * Q - 1 / n * np.ones(n)\n",
    "    \n",
    "    lambdas, vectors = np.linalg.eigh(R)\n",
    "    sort = lambdas.argsort()\n",
    "    lambdas = lambdas[sort]\n",
    "    vectors = vectors[:,sort]\n",
    "    l1 = lambdas[-1]\n",
    "    z = vectors[:,-1]\n",
    "    \n",
    "    search = np.empty_like(A)\n",
    "    search[:] = np.nan\n",
    "    pairs = {}\n",
    "    for i, j in itertools.combinations(range(n), 2):\n",
    "        if (addremove == 1 and A[i][j] == 0) or (addremove == -1 and A[i][j] == 1):\n",
    "            dA = np.zeros_like(A)\n",
    "            dA[i, j] = addremove\n",
    "            dA[j, i] = addremove\n",
    "        else:\n",
    "            continue\n",
    "            \n",
    "        dQ = np.diag(dA.sum(1)) - dA\n",
    "        approx = z.T @ dQ @ z - (eps / l1) * z.T @ np.linalg.matrix_power(dQ, 2) @ z\n",
    "        pairs[(i, j)] = round(approx, 2)\n",
    "        if abs(approx) > 10e-5:\n",
    "            search[i, j] = approx\n",
    "                \n",
    "    s_val = np.nanmax(search)\n",
    "    best = {tuple(p) for p in np.argwhere(np.isclose(search, s_val))}\n",
    "    \n",
    "    return Res(pairs, best)\n",
    "    \n",
    "    \n",
    "def exact_He(A, addremove):\n",
    "    n = np.size(A, 1)\n",
    "\n",
    "    Q = np.diag(A.sum(1)) - A\n",
    "    \n",
    "    lambdas, vectors = np.linalg.eigh(Q)\n",
    "    sort = lambdas.argsort()\n",
    "    lambdas = lambdas[sort]\n",
    "    vectors = vectors[:,sort]\n",
    "    lambdas = np.insert(lambdas, 0, -1)  # Insert an extra element so we can use 1-indexing\n",
    "    vectors = np.insert(vectors, 0, -1, axis=1)\n",
    "    \n",
    "    sum_range = set(range(1, n+1)) - {2}\n",
    "    search = np.empty_like(A)\n",
    "    search[:] = np.nan\n",
    "    pairs = {}\n",
    "    for i, j in itertools.combinations(range(n), 2):\n",
    "        if (addremove == 1 and A[i][j] == 0) or (addremove == -1 and A[i][j] == 1):\n",
    "            dA = np.zeros_like(A)\n",
    "            dA[i, j] = addremove\n",
    "            dA[j, i] = addremove\n",
    "        else:\n",
    "            continue\n",
    "            \n",
    "        dQ = np.diag(dA.sum(1)) - dA\n",
    "        \n",
    "        approx = (vectors[:,2].T @ dQ @ vectors[:,2] \n",
    "                  + sum(pow(vectors[:,k].T @ dQ @ vectors[:,2], 2) / (lambdas[2] - lambdas[k]) for k in sum_range))\n",
    "        pairs[(i, j)] = round(approx, 2)\n",
    "        if abs(approx) > 10e-5:\n",
    "            search[i, j] = approx\n",
    "                \n",
    "    s_val = np.nanmax(search)\n",
    "    best = {tuple(p) for p in np.argwhere(np.isclose(search, s_val))}\n",
    "    \n",
    "    errors = None\n",
    "    # for p in best:\n",
    "    #     dA = np.zeros_like(A)\n",
    "    #     dA[p[0], p[1]] = addremove\n",
    "    #     dA[p[1], p[0]] = addremove\n",
    "    #     dQ = np.diag(dA.sum(1)) - dA\n",
    "    #     errors[p] = np.linalg.norm(dQ, 'fro') ** 3\n",
    "    \n",
    "    return Res(pairs, best), errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import copy\n",
    "import plotly.graph_objects as pgo\n",
    "import plotly.subplots as psub\n",
    "import plotly.express as px\n",
    "from Utils.plotting_funcs import plotly_nx\n",
    "\n",
    "\n",
    "def make_analysis(k, A_start, p=False):\n",
    "    x = np.linspace(0, 1, 50)\n",
    "    N = A_start.shape[0]\n",
    "    \n",
    "    prototype = {1: None, -1: None}\n",
    "    symbols = {'1st': 'square', '2nd': 'circle', 'exact': 'x'}\n",
    "    results = {'1st': copy(prototype), '2nd': copy(prototype), 'exact': copy(prototype)}\n",
    "    errors = {'1st': copy(prototype), '2nd': copy(prototype), 'exact': copy(prototype)}\n",
    "\n",
    "    # Initial lambda value and max change estimate.\n",
    "    l2_0, lambda_mul, f, results['1st'][1] = first_approx_Ghosh(A_start, addremove=1)\n",
    "    _, _, _, results['1st'][-1] = first_approx_Ghosh(A_start, addremove=-1)\n",
    "    \n",
    "    # If lambda2 is unique, calculate other estimates as well.\n",
    "    if lambda_mul == 1:\n",
    "        results['2nd'][1] = second_approx_He(A_start, addremove=1)\n",
    "        results['2nd'][-1] = second_approx_He(A_start, addremove=-1)\n",
    "        \n",
    "        results['exact'][1], errors['exact'][1] = exact_He(A_start, addremove=1)\n",
    "        results['exact'][-1], errors['exact'][-1] = exact_He(A_start, addremove=-1)\n",
    "    # Otherwise, calculate node centralities.\n",
    "    else:\n",
    "        G = nx.from_numpy_array(A_start)\n",
    "        centrality = nx.closeness_centrality(G)\n",
    "\n",
    "    # Numerically calculate real lambda2 changes.\n",
    "    sens_data = {}\n",
    "    trend = {}\n",
    "    for i in range(0, N):\n",
    "        for j in range(i + 1, N):\n",
    "            sens_data[(i,j)] = []\n",
    "            A = A_start.copy()\n",
    "\n",
    "            # Calculate continuous changes in l2 when changing links.\n",
    "            for t in x:\n",
    "                A[i][j] = t\n",
    "                A[j][i] = t\n",
    "                l2 = calc_lambda(A)[0]\n",
    "                sens_data[(i, j)].append(l2)\n",
    "                trend[(i, j)] = 'dash' if A_start[i][j] else 'solid'\n",
    "\n",
    "    # Make plots.\n",
    "    fig = psub.make_subplots(rows=1, cols=2)\n",
    "    nodes, edges = plotly_nx(nx.from_numpy_array(A_start))\n",
    "    fig.add_trace(nodes, row=1, col=1)\n",
    "    fig.add_trace(edges, row=1, col=1)\n",
    "    \n",
    "    def add_markers(data, pair_value, err_value, addremove, symbol, color):\n",
    "        if addremove == 1:\n",
    "            x = 1\n",
    "            y = data[0] + pair_value\n",
    "        elif addremove == -1:\n",
    "            x = 0\n",
    "            y = data[-1] + pair_value\n",
    "        else:\n",
    "            return\n",
    "        \n",
    "        err = None\n",
    "        if err_value is not None:\n",
    "            err = dict(type='data', array=[err_value])\n",
    "        \n",
    "        trace = pgo.Scatter(x=[x], y=[y], error_y=err, mode='markers', \n",
    "                            marker=dict(size=8, symbol=symbol, color=color),\n",
    "                            showlegend=False)\n",
    "        return trace\n",
    "        \n",
    "    mem = set()\n",
    "    col_iter = itertools.cycle(px.colors.qualitative.Plotly)\n",
    "    for edge in sens_data:\n",
    "        # if trend[edge] == 'solid':\n",
    "        #     continue\n",
    "        color = next(col_iter)\n",
    "        fig.add_trace(\n",
    "            pgo.Scatter(x=x, y=sens_data[edge], name=str(edge),\n",
    "                        mode='lines', line=dict(dash=trend[edge], color=color)),\n",
    "            row=1, col=2\n",
    "        )\n",
    "        \n",
    "        for method in results:\n",
    "            for action in results[method]:\n",
    "                id = (method, action)\n",
    "                output = results[method][action]\n",
    "                err = errors[method][action]\n",
    "                if id not in mem and output is not None and output.best is not None and edge in output.best:\n",
    "                    if err is None:\n",
    "                        err = {}\n",
    "                    trace = add_markers(sens_data[edge], output.pair[edge], err.get(edge, None), action, symbols[method], color)\n",
    "                    fig.add_trace(trace, row=1, col=2)\n",
    "                    mem.add(id)\n",
    "\n",
    "            \n",
    "    fig.add_trace(pgo.Scatter(x=[0, 1], y=[l2_0, l2_0 + 1], name='+ref', mode='lines', line=dict(dash='dot', color='black')), row=1, col=2)\n",
    "    fig.add_trace(pgo.Scatter(x=[0, 1], y=[l2_0 - 1, l2_0], name='-ref', mode='lines', line=dict(dash='dot', color='black')), row=1, col=2)\n",
    "    for method in results:\n",
    "        fig.add_trace(pgo.Scatter(x=[0], y=[0], name=method, mode='markers', visible='legendonly',\n",
    "                                  marker=dict(size=8, symbol=symbols[method], color='black')), \n",
    "                      row=1, col=2)\n",
    "    fig.update_layout(title=dict(text=f'Graph {k} (l2 = {l2_0}, f = {f})'),\n",
    "                      width=750, height=600,\n",
    "                      margin=dict(l=50, r=50, t=80, b=200),\n",
    "                      )\n",
    "\n",
    "    # Print results.\n",
    "    if lambda_mul == 1:\n",
    "        def gen_annot(result):\n",
    "            if result is None:\n",
    "                return \"\"\n",
    "            \n",
    "            pairs = result.pair\n",
    "            best = result.best\n",
    "            return \", \".join(f'<b>{pair}={val}</b>' if pair in best else f'{pair}={val}' for pair, val in sorted(pairs.items()))\n",
    "            \n",
    "        annot_kwargs = dict(align='left', showarrow=False, xref='paper', yref='paper')\n",
    "        fig.add_annotation(text=\"<b>Adding links</b><br>\"\n",
    "                        + \"<br>\".join(gen_annot(results[key][1]) for key in sorted(results)),\n",
    "                        x=0.0, y=-0.3, **annot_kwargs)\n",
    "        fig.add_annotation(text=\"<b>Removing links</b><br>\" \n",
    "                        + \"<br>\".join(gen_annot(results[key][-1]) for key in sorted(results)),\n",
    "                        x=0.0, y=-0.55, **annot_kwargs)\n",
    "    else:\n",
    "        annot_kwargs = dict(align='left', showarrow=False, xref='paper', yref='paper')\n",
    "        fig.add_annotation(text=f\"Lambda2 multiplicity is {lambda_mul}.\", x=0.0, y=-0.2, **annot_kwargs)  \n",
    "        fig.add_annotation(text=\"Centralities: <br>\" \n",
    "                           + \", \".join(f\"({k})={v:.2f}\" for k, v in sorted(centrality.items(), key=lambda x: x[1])),\n",
    "                           x=0.0, y=-0.4, **annot_kwargs)  \n",
    "        \n",
    "            \n",
    "    fig.show()\n",
    "\n",
    "\n",
    "# A = np.array([\n",
    "#     [0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0],\n",
    "#     [1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
    "#     [0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "#     [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
    "#     [0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
    "#     [0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
    "#     [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
    "#     [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1],\n",
    "#     [0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
    "#     [1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
    "#     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
    "#     [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0],\n",
    "#     [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0],\n",
    "#     [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1],\n",
    "#     [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0],\n",
    "# ], dtype=float\n",
    "# )\n",
    "\n",
    "# gs = {\"A\": A}\n",
    "\n",
    "for k, A_start in enumerate(gs.values()):\n",
    "    make_analysis(k, A_start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HACK: https://github.com/microsoft/vscode-jupyter/issues/8131#issuecomment-1589961116\n",
    "import plotly\n",
    "from IPython.display import display, HTML\n",
    "plotly.offline.init_notebook_mode()\n",
    "display(HTML(\n",
    "    '<script type=\"text/javascript\" async src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_SVG\"></script>'\n",
    "))\n",
    "\n",
    "import plotly.graph_objects as pgo\n",
    "import plotly.subplots as psub\n",
    "from Utils.plotting_funcs import plotly_nx\n",
    "\n",
    "\n",
    "def make_analysis(k, A_start, p=False, save=False):\n",
    "    x = np.linspace(0, 1, 50)\n",
    "    N = A_start.shape[0]\n",
    "\n",
    "    # Initial lambda value and max change estimate.\n",
    "    init_lambda, addmax_est, addmax_links, f = calc_lambda_old(A_start, np.nanmax, addremove=1, p=False)\n",
    "    _, addmin_est, addmin_links, _ = calc_lambda_old(A_start, np.nanmin, addremove=1, p=False)\n",
    "    _, remmax_est, remmax_links, _ = calc_lambda_old(A_start, np.nanmax, addremove=-1, p=False)\n",
    "    _, remmin_est, remmin_links, _ = calc_lambda_old(A_start, np.nanmin, addremove=-1, p=False)\n",
    "\n",
    "    sens_data = {}\n",
    "    trend = {}\n",
    "    for i in range(0, N):\n",
    "        for j in range(i + 1, N):\n",
    "            sens_data[(i,j)] = []\n",
    "            A = A_start.copy()\n",
    "\n",
    "            # Calculate continuous changes in l2 when changing links.\n",
    "            for t in x:\n",
    "                A[i][j] = t\n",
    "                A[j][i] = t\n",
    "                l2 = calc_lambda_old(A, None)[0]\n",
    "                sens_data[(i, j)].append(l2)\n",
    "                trend[(i, j)] = 'dash' if A_start[i][j] else 'solid'\n",
    "\n",
    "            # Something else\n",
    "\n",
    "    # Make plots.\n",
    "    fig = psub.make_subplots(rows=1, cols=2)\n",
    "    # Left subplot - graph\n",
    "    nodes, edges = plotly_nx(nx.from_numpy_array(A_start))\n",
    "    fig.add_trace(nodes, row=1, col=1)\n",
    "    fig.add_trace(edges, row=1, col=1)\n",
    "    fig.update_xaxes(showticklabels=False, row=1, col=1)\n",
    "    fig.update_yaxes(showticklabels=False, row=1, col=1)\n",
    "    # Right subplot - sensitivity\n",
    "    for edge in sens_data:\n",
    "        fig.add_trace(\n",
    "            pgo.Scatter(x=x, y=sens_data[edge], name=str(edge),\n",
    "                        mode='lines', line=dict(dash=trend[edge])),\n",
    "            row=1, col=2\n",
    "        )\n",
    "    fig.update_xaxes(title_text='$\\large\\mathrm{Edge\\ weight}\\ a_{ij}$', title_standoff=5, row=1, col=2)\n",
    "    fig.update_yaxes(title_text='$\\large\\mathrm{Algebraic\\ connectivity}\\ \\lambda_2$', title_standoff=5, row=1, col=2)\n",
    "    fig.update_layout(title=dict(text=f'Graph {k} (l2 = {init_lambda}, f = {f})'),\n",
    "                      width=750, height=650,\n",
    "                      margin=dict(l=50, r=50, t=80, b=200),\n",
    "                      font=dict(size=16),\n",
    "                      )\n",
    "\n",
    "    # Print results.\n",
    "    def gen_annot(est, links,):\n",
    "        return (f'Estimated delta = {est}<br>'\n",
    "                f'Links maximizing delta = {links}<br>')\n",
    "    annot_kwargs = dict(align='left', showarrow=False, xref='paper', yref='paper')\n",
    "\n",
    "    fig.add_annotation(text=\"<b>Adding max link</b><br>\" + gen_annot(addmax_est, addmax_links), x=0.0, y=-0.4, **annot_kwargs)\n",
    "    fig.add_annotation(text=\"<b>Adding min link</b><br>\" + gen_annot(addmin_est, addmin_links), x=0.0, y=-0.6, **annot_kwargs)\n",
    "    fig.add_annotation(text=\"<b>Removing max link</b><br>\" + gen_annot(remmax_est, remmax_links), x=1, y=-0.4, **annot_kwargs)\n",
    "    fig.add_annotation(text=\"<b>Removing min link</b><br>\" + gen_annot(remmin_est, remmin_links), x=1, y=-0.6, **annot_kwargs)\n",
    "    fig.show()\n",
    "    \n",
    "    if save:\n",
    "        fig.write_image(f'l2_function_{k}.{save}')\n",
    "\n",
    "\n",
    "for k, A_start in enumerate(gs.values()):\n",
    "    if k in [3, 46]:\n",
    "        make_analysis(k, A_start, save='pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Check the consistency of $$\\Delta \\lambda_{2, max} = \\max(f_i - f_j)^2$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "count = Counter()\n",
    "\n",
    "\n",
    "for k, A_start in enumerate(gs):\n",
    "    if k in []:\n",
    "        debug = True\n",
    "    else:\n",
    "        debug = False\n",
    "    init_lambda, delta_est, init_links, _ = calc_lambda_old(A_start, np.nanmax, addremove=1, p=debug)\n",
    "\n",
    "    n = A_start.shape[0]\n",
    "    max_lambda = init_lambda\n",
    "    max_links = set()\n",
    "    for i in range(0, NV):\n",
    "        for j in range(i + 1, NV):\n",
    "            if A_start[i][j] == 0:\n",
    "                A = A_start.copy()\n",
    "                A[i][j] = 1\n",
    "                A[j][i] = 1\n",
    "\n",
    "                new_lambda = calc_lambda_old(A, np.nanmax)[0]\n",
    "                if (new_lambda - max_lambda) > 10e-5:\n",
    "                    max_lambda = new_lambda\n",
    "                    max_links = {(i, j)}\n",
    "                elif abs(new_lambda - max_lambda) < 10e-5 and abs(new_lambda - init_lambda) > 10e-5:\n",
    "                    max_links.add((i, j))\n",
    "\n",
    "    print(f'Graph {k}...', end=' ')\n",
    "\n",
    "    if max_links == init_links or not max_links or init_links.issubset(max_links):\n",
    "        out = 'OK'\n",
    "    elif max_links.issubset(init_links):\n",
    "        out = 'Partial'\n",
    "    else:\n",
    "        out = 'FAIL'\n",
    "        make_analysis(k, A_start)\n",
    "    count[out] += 1\n",
    "\n",
    "    print(f'{out} (l2o={init_lambda}, l2f={max_lambda}, est={init_links}, act={max_links})', flush=True)\n",
    "\n",
    "total = sum(count.values())\n",
    "print('=========================')\n",
    "print(f\"OK     : {count['OK']}/{total} [{count['OK'] / total * 100:.2f} %]\")\n",
    "print(f\"Partial: {count['Partial']}/{total} [{count['Partial'] / total * 100:.2f} %]\")\n",
    "print(f\"FAIL   : {count['FAIL']}/{total} [{count['FAIL'] / total * 100:.2f} %]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def select_link(A, addremove):\n",
    "    L = np.diag(A.sum(1)) - A\n",
    "    lambdas, vectors = np.linalg.eigh(L)\n",
    "    sort = lambdas.argsort()\n",
    "    lambdas = lambdas[sort]\n",
    "    vectors = vectors[:, sort]\n",
    "\n",
    "    l2 = lambdas[1]\n",
    "    f = vectors[:, 1]\n",
    "\n",
    "    search = []\n",
    "    f = np.around(f, 4)\n",
    "    for i, j in itertools.combinations(range(len(f)), 2):\n",
    "        if abs(f[i] - f[j]) > 10e-5 and ((addremove == \"ADD\" and A[i][j] == 0) or (addremove == \"REM\" and A[i][j] == 1)):\n",
    "            search.append((round((f[i] - f[j]) ** 2, 4), (i, j)))\n",
    "\n",
    "    if not search:\n",
    "        return None\n",
    "\n",
    "    if addremove == \"ADD\":\n",
    "        f_val, link = max(search)\n",
    "    else:\n",
    "        f_val, link = min(search)\n",
    "\n",
    "    return l2, f_val, link\n",
    "\n",
    "\n",
    "starting_graph = 'G6,102'\n",
    "ref_lambda = [1, 3, 2]\n",
    "\n",
    "data_folder = Path.cwd() / '../Data'\n",
    "with open(data_folder / f'UniqueGraphs_{starting_graph[1]}.npz', 'rb') as stream:\n",
    "    loaded = np.load(stream)\n",
    "    graphs = {x: loaded[x] for x in loaded}\n",
    "\n",
    "k = 0\n",
    "A = graphs[starting_graph]\n",
    "history = [A.copy()]\n",
    "addremove = \"ADD\"\n",
    "l2 = 0\n",
    "\n",
    "for ref in ref_lambda:\n",
    "    user_input = 'Y'\n",
    "\n",
    "    print(f'ref={ref}')\n",
    "    while user_input != 'n':\n",
    "        l2, _, _, = select_link(A, addremove)\n",
    "\n",
    "        if l2 < ref - 0.2:\n",
    "            addremove = \"ADD\"\n",
    "        elif l2 > ref + 0.2:\n",
    "            addremove = \"REM\"\n",
    "        else:\n",
    "            break\n",
    "\n",
    "        _, _, pair, = select_link(A, addremove)\n",
    "        val = 1 if addremove == \"ADD\" else 0\n",
    "        A[pair[0]][pair[1]] = val\n",
    "        A[pair[1]][pair[0]] = val\n",
    "        history.append(A.copy())\n",
    "\n",
    "        print(f\"k={k} | l2={l2:6.4f} {addremove} {pair}' > Continue? (Y/n)\", flush=True)\n",
    "        time.sleep(0.5)\n",
    "        user_input = input()\n",
    "\n",
    "        k += 1\n",
    "\n",
    "\n",
    "for k, A in enumerate(history):\n",
    "   make_analysis(k, A)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
